**=====================================================**

# Machine Failure Analysis 
Noah MacGillivray | BIT-446 Assignment(T5) | Summer 2025 

Model Evaluation of a k-NN Classification Model

**Environment:** Ubuntu, VS Code

**=====================================================**

## Required packages 
```{r}
# Load packages
library(readxl)
library(skimr)
library(dplyr)
library(class)
library(caTools)
library(caret)
library(ggplot2)
library(lattice)
library(metrica)

cat("All packages loaded successfully!\n")
```

## Data Import and Initial Exploration  
```{r}
failure_rate <- read_excel("BIT-446-RS-T4-T5-FailureRate.xlsx", n_max = 300)

# Print head
head(failure_rate)

# Print tail
tail(failure_rate)

# Print skimr dataset summary
skim(failure_rate)

# Machine number failure rate summary
model_version_summary <- failure_rate %>%
  group_by(model_version) %>%
  summarise(
    total_units = n(),
    failure_rate = mean(failure),
    .groups = "drop"
  )
# Prints the summary 
print(model_version_summary)
```

## Data Preparation
```{r}
# Normalize only the features of interest; default is z-score
failure_rate$hours_run <- as.vector(scale(failure_rate$hours_run))

failure_rate$avg_hours_between_maint <-
  as.vector(scale(failure_rate$avg_hours_between_maint))


failure_rate$failure <- as.factor(failure_rate$failure)
```


## General impressions from summary 



## Data splitting for k-NN training (stratified)

```{r}
# Set seed for reproducible results
set.seed(44)

# Stratified random split 70/30
sample <- sample.split(failure_rate$failure, SplitRatio = 0.7)

# Distribute the split data to training and testing
train_failure <- subset(failure_rate, sample == TRUE)
test_failure <- subset(failure_rate, sample == FALSE)
```

## Apply k-NN (stratified) 
```{r}
# Apply k-NN classification with hours_run and avg_hours_between_maint
failure_knn <- knn(
  train_failure[c("hours_run", "avg_hours_between_maint")],
  test_failure[c("hours_run", "avg_hours_between_maint")],
  cl = train_failure$failure,
  k = 5
)
```

## Data splitting for k-NN (k-folds)

```{r}
# Set seed for reproducibility
set.seed(44)

# Set up 10 fold cross validation via caret package
ctrl <- trainControl(
  method = "cv",           # Cross-validation
  number = 10,             # 10 folds
  savePredictions = "final" # Save predictions for confusion matrix
)

# Define k values to test
k_grid <- data.frame(k = c(3, 5, 7, 9, 11, 13, 15, 17))
```


## Apply k-NN (k-folds)
```{r}
# Apply k-NN with k-fold cross-validation
knn_kfolds_model <- train(
  failure ~ hours_run + avg_hours_between_maint,
  data = failure_rate,
  method = "knn",
  trControl = ctrl,
  tuneGrid = k_grid,
  metric = "Accuracy"
)
```


## Model Evaluation Metrics (stratified)
```{r}
# Bind the k-NN model with our data frame
test_obs_pred <- data.frame(test_failure, failure_knn)

# Display confusion matrix
confusionMatrix(test_obs_pred$failure_knn,
                test_obs_pred$failure,
                mode = "prec_recall")

# Comprehensive metrics summary using metrica package
obs <- as.numeric(paste(test_failure$failure))
pred <- as.numeric(paste(test_obs_pred$failure_knn))
data <- data.frame(cbind(obs, pred))

# Create comprehensive metrics summary using metrica package
metrics_summary(
  data = data,
  obs = obs,
  pred = pred,
  pos_level = 1,
  type = "classification"
)

# Provide model results using caret package
confusionMatrix(
  data = factor(pred),
  reference = factor(obs),
  mode = "prec_recall"
)
# Scatter plot
ggplot(test_obs_pred, aes(x = hours_run, y = avg_hours_between_maint, 
                          color = failure == failure_knn)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("FALSE" = "red", "TRUE" = "blue"),
                     name = "Prediction", labels = c("Wrong", "Correct")) +
  labs(title = "k-NN Machine Failure Predictions", 
       x = "Hours Run (normalized)",
       y = "Avg Hours Between Maintenance(normalized)") +
  theme_minimal()
```

## Model Evaluation Metrics (k-folds)

```{r}
# View results
print(knn_kfolds_model)

# Plot k value performance
plot(knn_kfolds_model)

# Get the best k value
cat("Best k value:", knn_kfolds_model$bestTune$k, "\n")

# Confusion matrix for best model compiles across all folds
caret_cm <- confusionMatrix(knn_kfolds_model$pred$pred,
                            knn_kfolds_model$pred$obs, mode = "prec_recall")
print(caret_cm)

# Comprehensive metrics using metrica package
obs_caret <- as.numeric(paste(knn_kfolds_model$pred$obs))
pred_caret <- as.numeric(paste(knn_kfolds_model$pred$pred))
caret_data <- data.frame(cbind(obs = obs_caret, pred = pred_caret))

metrics_summary(
  data = caret_data,
  obs = obs_caret,
  pred = pred_caret,
  pos_level = 1,
  type = "classification"
)

pred_indices <- knn_kfolds_model$pred$rowIndex

# Create data frame for plotting
kfold_plot_data <- data.frame(
  hours_run = failure_rate$hours_run[pred_indices],
  avg_hours_between_maint = failure_rate$avg_hours_between_maint[pred_indices],
  actual = knn_kfolds_model$pred$obs,
  predicted = knn_kfolds_model$pred$pred,
  correct = knn_kfolds_model$pred$obs == knn_kfolds_model$pred$pred
)

# Scatter plot
ggplot(kfold_plot_data,
       aes(x = hours_run, y = avg_hours_between_maint, color = correct)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_color_manual(values = c("FALSE" = "red", "TRUE" = "blue"),
                     name = "Prediction", labels = c("Wrong", "Correct")) +
  labs(title = "k-NN Machine Failure Predictions (K-Fold Cross-Validation)",
       subtitle = paste("Best k =", knn_kfolds_model$bestTune$k, "| Accuracy =",
                        round(max(knn_kfolds_model$results$Accuracy), 3)),
       x = "Hours Run (normalized)",
       y = "Avg Hours Between Maintenance (normalized)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```




## Conclusion and analysis 